#!/usr/bin/env python3
"""
ç®€å•çš„68tt.coæŠ“å–æµ‹è¯• - åŒ…å«å›¾ç‰‡ä¸‹è½½
"""

import requests
import os
from pathlib import Path
from urllib.parse import urljoin, urlparse
from bs4 import BeautifulSoup
import time

def download_with_assets():
    """ä½¿ç”¨requestsç›´æŽ¥æŠ“å–å¹¶ä¸‹è½½èµ„æº"""
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path("simple_scrape_output")
    output_dir.mkdir(exist_ok=True)
    assets_dir = output_dir / "assets"
    assets_dir.mkdir(exist_ok=True)
    
    # è®¾ç½®è¯·æ±‚å¤´
    headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    }
    
    # è¦æŠ“å–çš„é¡µé¢
    pages = [
        "https://68tt.co/cn/",
        "https://68tt.co/cn/about.html", 
        "https://68tt.co/cn/privacy.html"
    ]
    
    downloaded_images = []
    
    print("ðŸš€ å¼€å§‹ç®€å•æŠ“å–...")
    
    for i, url in enumerate(pages, 1):
        print(f"\n[{i}/{len(pages)}] å¤„ç†é¡µé¢: {url}")
        
        try:
            # èŽ·å–é¡µé¢å†…å®¹
            response = requests.get(url, headers=headers, timeout=30)
            if response.status_code != 200:
                print(f"âŒ é¡µé¢èŽ·å–å¤±è´¥: HTTP {response.status_code}")
                continue
                
            print(f"âœ… é¡µé¢èŽ·å–æˆåŠŸ: {len(response.text)} å­—ç¬¦")
            
            # è§£æžHTML
            soup = BeautifulSoup(response.text, 'html.parser')
            title = soup.title.string if soup.title else "Untitled"
            
            # ä¿å­˜HTML
            filename = f"page_{i}_{urlparse(url).path.strip('/').replace('/', '_') or 'index'}.html"
            html_path = output_dir / filename
            with open(html_path, 'w', encoding='utf-8') as f:
                f.write(response.text)
            
            print(f"ðŸ“„ HTMLä¿å­˜: {filename}")
            
            # æŸ¥æ‰¾å¹¶ä¸‹è½½å›¾ç‰‡
            images = soup.find_all('img', src=True)
            print(f"ðŸ–¼ï¸  å‘çŽ° {len(images)} ä¸ªå›¾ç‰‡")
            
            for j, img in enumerate(images):
                img_src = img['src']
                
                # å¤„ç†ç›¸å¯¹URL
                if img_src.startswith('//'):
                    img_url = 'https:' + img_src
                elif img_src.startswith('/'):
                    img_url = 'https://68tt.co' + img_src
                elif not img_src.startswith('http'):
                    img_url = urljoin(url, img_src)
                else:
                    img_url = img_src
                
                # è·³è¿‡base64å›¾ç‰‡
                if img_url.startswith('data:'):
                    continue
                    
                # è·³è¿‡å·²ä¸‹è½½çš„å›¾ç‰‡
                if img_url in downloaded_images:
                    continue
                
                try:
                    print(f"  ðŸ“¥ ä¸‹è½½å›¾ç‰‡ {j+1}: {img_url}")
                    img_response = requests.get(img_url, headers=headers, timeout=30)
                    
                    if img_response.status_code == 200:
                        # ç”Ÿæˆæ–‡ä»¶å
                        img_filename = os.path.basename(urlparse(img_url).path)
                        if not img_filename or '.' not in img_filename:
                            # æ ¹æ®å†…å®¹ç±»åž‹ç”Ÿæˆæ‰©å±•å
                            content_type = img_response.headers.get('content-type', '')
                            if 'png' in content_type:
                                ext = '.png'
                            elif 'jpeg' in content_type or 'jpg' in content_type:
                                ext = '.jpg'
                            elif 'gif' in content_type:
                                ext = '.gif'
                            elif 'svg' in content_type:
                                ext = '.svg'
                            else:
                                ext = '.jpg'
                            img_filename = f"image_{hash(img_url) % 10000}{ext}"
                        
                        # ç¡®ä¿æ–‡ä»¶åå”¯ä¸€
                        counter = 1
                        original_filename = img_filename
                        while (assets_dir / img_filename).exists():
                            name, ext = os.path.splitext(original_filename)
                            img_filename = f"{name}_{counter}{ext}"
                            counter += 1
                        
                        img_path = assets_dir / img_filename
                        with open(img_path, 'wb') as f:
                            f.write(img_response.content)
                        
                        downloaded_images.append(img_url)
                        print(f"    âœ… ä¿å­˜: {img_filename} ({len(img_response.content)} å­—èŠ‚)")
                    else:
                        print(f"    âŒ ä¸‹è½½å¤±è´¥: HTTP {img_response.status_code}")
                        
                except Exception as e:
                    print(f"    âŒ å›¾ç‰‡ä¸‹è½½é”™è¯¯: {e}")
                
                # é¿å…è¿‡äºŽé¢‘ç¹çš„è¯·æ±‚
                time.sleep(0.5)
            
        except Exception as e:
            print(f"âŒ é¡µé¢å¤„ç†é”™è¯¯: {e}")
        
        # é¡µé¢é—´ç¨ä½œåœé¡¿
        time.sleep(1)
    
    # ç”ŸæˆæŠ¥å‘Š
    print(f"\nðŸ“Š æŠ“å–å®Œæˆç»Ÿè®¡:")
    
    all_files = list(output_dir.rglob("*"))
    files = [f for f in all_files if f.is_file()]
    
    html_files = [f for f in files if f.suffix == '.html']
    img_files = [f for f in files if f.suffix.lower() in ['.jpg', '.jpeg', '.png', '.gif', '.webp', '.svg']]
    
    print(f"ðŸ“„ HTML æ–‡ä»¶: {len(html_files)} ä¸ª")
    print(f"ðŸ–¼ï¸  å›¾ç‰‡æ–‡ä»¶: {len(img_files)} ä¸ª")
    print(f"ðŸ“ æ€»æ–‡ä»¶: {len(files)} ä¸ª")
    print(f"ðŸ’¾ è¾“å‡ºç›®å½•: {output_dir}")
    
    # æ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨
    print(f"\nðŸ“‹ æ–‡ä»¶åˆ—è¡¨:")
    for file in sorted(files):
        size = file.stat().st_size
        if size > 1024:
            size_str = f"{size/1024:.1f}KB"
        else:
            size_str = f"{size}B"
        print(f"  - {file.name} ({size_str})")

if __name__ == "__main__":
    download_with_assets()
